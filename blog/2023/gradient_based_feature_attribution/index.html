<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Gradient-based feature attribution for Vision | Christos  Athanasiadis</title>
    <meta name="author" content="Christos  Athanasiadis">
    <meta name="description" content="This page's main focus is to analyze a branch of explainable &amp; interpretable AI (XAI) called posthoc XAI. We will analyze theory, taxonomy, applications, shortcomings of posthoc XAI approaches and apply them on image classification using popular CNN architectures and explain their black box nature. Part of the assessemnet for this tutorial/workshop, will be some research questions that needs be answered by you. These questions can be found all over this blogspot using the &lt;mark&gt;TOSUBMIT&lt;/mark&gt; tag and will be summarized them at the end of the blogspot.">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%98%8E&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/kristosh/assets/css/main.css">
    <link rel="canonical" href="https://kristosh.github.io/kristosh/blog/2023/gradient_based_feature_attribution/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/kristosh/assets/js/theme.js"></script>
    <script src="/kristosh/assets/js/dark_mode.js"></script>
    


    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/kristosh/assets/js/distillpub/template.v2.js"></script>
    <script src="/kristosh/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/kristosh/assets/js/distillpub/overrides.js"></script>
    
    <!-- Page/Post style -->
    <style type="text/css">
      .fake-img {
  background: #bbb;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 0px 4px rgba(0, 0, 0, 0.1);
  margin-bottom: 12px;
} .fake-img p {
  font-family: monospace;
  color: white;
  text-align: left;
  margin: 12px 0;
  text-align: center;
  font-size: 16px;
}

    </style>
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "Gradient-based feature attribution for Vision",
      "description": "This page's main focus is to analyze a branch of explainable & interpretable AI (XAI) called posthoc XAI. We will analyze theory, taxonomy, applications, shortcomings of posthoc XAI approaches and apply them on image classification using popular CNN architectures and explain their black box nature. Part of the assessemnet for this tutorial/workshop, will be some research questions that needs be answered by you. These questions can be found all over this blogspot using the <mark>TOSUBMIT</mark> tag and will be summarized them at the end of the blogspot.",
      "published": "May 13, 2023",
      "authors": [
        {
          "author": "Christos Athanasiadis",
          "authorURL": "https://www.linkedin.com/in/christos-athanasiadis-a3b51035/",
          "affiliations": [
            {
              "name": "UvA, Interpretability and Explainability in AI",
              "url": ""
            }
          ]
        },
        {
          "author": "Peter Heemskerk",
          "authorURL": "",
          "affiliations": [
            {
              "name": "UvA, Interpretability and Explainability in AI",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/kristosh//"><span class="font-weight-bold">ChristosÂ </span>Athanasiadis</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/kristosh/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/kristosh/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/kristosh/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/kristosh/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>Gradient-based feature attribution for Vision</h1>
        <p>This page's main focus is to analyze a branch of explainable &amp; interpretable AI (XAI) called posthoc XAI. We will analyze theory, taxonomy, applications, shortcomings of posthoc XAI approaches and apply them on image classification using popular CNN architectures and explain their black box nature. Part of the assessemnet for this tutorial/workshop, will be some research questions that needs be answered by you. These questions can be found all over this blogspot using the <mark>TOSUBMIT</mark> tag and will be summarized them at the end of the blogspot.</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#introduction">Introduction</a></div>
            <div><a href="#introduction-to-xai">Introduction to XAI</a></div>
            <div><a href="#gradient-based-methods">Gradient-based methods</a></div>
            <div><a href="#conclusion">Conclusion</a></div>
            
          </nav>
        </d-contents>

        <h1 id="gradient-based-feature-attribution-for-vision">Gradient-based feature attribution for Vision</h1>

<p>Before starting with the explanation of the gradient-based methodologies, we provide some useful code for all the necessarry packages loacing a pre-trained VGG model (in Imagenet) but also code to load a image for a local directory in PyTorch. You can access the code of this tutorial in the following <a href="https://colab.research.google.com/drive/1zWmtpOTXfxv1Hxwl7G5heU73vz90iNhl?usp=sharing" rel="external nofollow noopener" target="_blank">google colab link</a>.</p>

<p>The packages that you will need to import are the following ones:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># set-up environment
</span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torchvision</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="n">cv2</span>
<span class="kn">import</span> <span class="n">os</span>  <span class="c1"># necessary
</span><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="c1">#from google.colab.patches import cv2_imshow   # specific for colab
</span><span class="n">os</span><span class="p">.</span><span class="n">environ</span><span class="p">[</span><span class="sh">'</span><span class="s">KMP_DUPLICATE_LIB_OK</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="sh">'</span><span class="s">True</span><span class="sh">'</span>
</code></pre></div></div>

<h3 id="load-a-pretrained-model">Load a pretrained model</h3>

<p>We will make use of the VGG19 CNN network and ImageNet.</p>

<ul>
  <li>ImageNet is a large collection of images.</li>
  <li>VGG19 is a convolutional neural network architecture.</li>
  <li>
    <p>We can load a version that is trained on ImageNet and that can detect objects in 1000 classes.</p>
  </li>
  <li>Read about and understand VGG ConvNet and Imagenet for background.</li>
</ul>

<p>The first step is that using the pytorch library, we load the pretrained version of VGG19.</p>

<p>Since we will not train the model we set the model in evaluation mode.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load model
# model_type = 'vgg19'
</span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="nf">vgg19</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># run it on a GPU if available:
</span><span class="n">cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda:0</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda:</span><span class="sh">'</span><span class="p">,</span> <span class="n">cuda</span><span class="p">,</span> <span class="sh">'</span><span class="s">device:</span><span class="sh">'</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># set model to evaluation
</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
</code></pre></div></div>

<p>The output should look like this:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Output</span> <span class="n">exceeds</span> <span class="n">the</span> <span class="n">size</span> <span class="n">limit</span><span class="p">.</span> <span class="n">Open</span> <span class="n">the</span> <span class="n">full</span> <span class="n">output</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">a</span> <span class="n">text</span> <span class="nf">editorVGG</span><span class="p">(</span>
  <span class="p">(</span><span class="n">features</span><span class="p">):</span> <span class="nc">Sequential</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">0</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">1</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">2</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">3</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">7</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">8</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">9</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">10</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">11</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">12</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">13</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">14</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">15</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">16</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">17</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">18</span><span class="p">):</span> <span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">19</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">20</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">21</span><span class="p">):</span> <span class="nc">Conv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="p">(</span><span class="mi">22</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="bp">...</span>
    <span class="p">(</span><span class="mi">4</span><span class="p">):</span> <span class="nc">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">5</span><span class="p">):</span> <span class="nc">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="p">(</span><span class="mi">6</span><span class="p">):</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
  <span class="p">)</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="load-and-preprocess-the-images">Load and preprocess the images:</h3>

<p>We have provided a few images of wildlife, but please also use you own imagery. Set the path to your data-file and load an image.</p>

<p>VGG-19 works best if image is normalised. Image should also be in the correct tensor format.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pre_processing</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">cuda</span><span class="p">):</span>
    <span class="c1"># Students should transpose the image to the correct tensor format. 
</span>    <span class="c1"># Students should ensure that gradient for input is calculated       
</span>    <span class="c1"># set the GPU device
</span>    <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
        <span class="n">torch_device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda:0</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">torch_device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># normalise for ImageNet
</span>    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span> <span class="o">/</span> <span class="mi">255</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="p">(</span><span class="n">obs</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>

    <span class="c1"># make tensor format that keeps track of gradient
</span>    <span class="c1"># BEGIN for students to do
</span>    <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>       
    <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
    <span class="n">obs_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch_device</span><span class="p">)</span>
    <span class="c1"># END for students to do
</span>    <span class="k">return</span> <span class="n">obs_tensor</span>

</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="c1">#The line above is necesary to show Matplotlib's plots inside a Jupyter Notebook
</span><span class="kn">from</span> <span class="n">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># read the image and convert it - Set your pathto the image
</span><span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">elephant-zebra.png</span><span class="sh">'</span><span class="p">)</span>
<span class="c1">#img = cv2.imread(datafiles+ 'R.png')
#img = cv2.imread(datafiles+ 'elephant/Elephant2.jpeg')
# img = cv2.imread(datafiles+ 'shark/Shark1.jpeg')
</span><span class="nf">if </span><span class="p">(</span><span class="nf">type</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="ow">is</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">img:</span><span class="sh">'</span><span class="p">,</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>


<span class="k">else</span><span class="p">:</span>
  <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">image not found - set your path to the image</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">frameon</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">facecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">white</span><span class="sh">'</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nc">Axes</span><span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_axis_off</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">add_axes</span><span class="p">(</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">img</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div>

<h3 id="predict-class">Predict class</h3>

<p>We can easily predict the class, and the softmax score of that prediction:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">target_label_idx</span><span class="p">,</span> <span class="n">cuda</span><span class="p">):</span>
    <span class="c1"># Makes prediction after preprocessing image 
</span>    <span class="c1"># Note that output should be torch.tensor on cuda
</span>    <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>                        
    <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># calc output from model 
</span>    <span class="k">if</span> <span class="n">target_label_idx</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">target_label_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">output</span><span class="p">.</span><span class="nf">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">target_label_idx</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span> 
    <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
      <span class="n">index</span> <span class="o">=</span> <span class="n">index</span><span class="p">.</span><span class="nf">cuda</span><span class="p">()</span>                     <span class="c1"># calc prediction
</span>    <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="nf">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>           <span class="c1"># gather functionality of pytorch
</span>    <span class="k">return</span> <span class="n">target_label_idx</span><span class="p">,</span> <span class="n">output</span> 

<span class="c1"># test preprocessing
# you can check that the VGG network gives a correct prediction. E.g. 385 and 386 are 'Indian Elephant'and 'African Elephant'
</span><span class="nb">input</span> <span class="o">=</span> <span class="nf">pre_processing</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span>          <span class="c1"># preprocess: image (normalise, transpose, make tensor on cuda, requires_grad=True)
</span><span class="n">output</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">output:</span><span class="sh">'</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
</code></pre></div></div>

<p><strong>TODO 1</strong></p>
<ul>
  <li>Upload at least two images to your directory with the first one containing a single animal and the second image with two animals.</li>
  <li>Run the classifier with both images.</li>
  <li>Look up the predicted categories and the ImageNet labels.</li>
  <li>Look up the indices corresponsing to each of the animals in your images.</li>
</ul>

<p>The following snippets might be useful:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">wget</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">raw</span><span class="p">.</span><span class="n">githubusercontent</span><span class="p">.</span><span class="n">com</span><span class="o">/</span><span class="n">pytorch</span><span class="o">/</span><span class="n">hub</span><span class="o">/</span><span class="n">master</span><span class="o">/</span><span class="n">imagenet_classes</span><span class="p">.</span><span class="n">txt</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="sh">"</span><span class="s">imagenet_classes.txt</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="n">s</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">f</span><span class="p">.</span><span class="nf">readlines</span><span class="p">()]</span>
<span class="nf">print</span><span class="p">(</span><span class="n">categories</span><span class="p">[</span><span class="mi">385</span><span class="p">])</span>
<span class="n">categories</span><span class="p">.</span><span class="nf">index</span><span class="p">(</span><span class="sh">'</span><span class="s">Indian elephant</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="compute-the-gradient-with-respect-to-the-input-pixels">Compute the gradient with respect to the input pixels</h3>

<p>Now that we can predict the class of an object, we will try to understand what image pixels are most important for the prediction using <em>feature attribution methods</em>. The first technique that we will make use is the saliency maps. In short this approach determines the gradient of the output w.r.t to the input.</p>

<p>The idea of Saliency maps (called <em> Vanilla Gradient </em> as well), introduced by Simonyan et al. (https://arxiv.org/pdf/1312.6034.pdf) as one of the first pixel attribution approaches. The core idea is really simple and what needs to be done is to calculate the gradient of the loss function for the class we are interested in with respect to the input features. This gives us a map of the size of the input features with negative to positive values.</p>

<p>The recipe for this approach is as follows:</p>

<ul>
  <li>
<strong>Perform a forward pass</strong> of the image ($\mathbf{x}_0$) of interest using the network $\mathcal{F}(\mathbf{x}_0)$.</li>
  <li>
<strong>Compute the gradient</strong> of class score of interest with respect to the input image ($\mathbf{x}_0$): $g(\mathbf{x}_0) = \frac{\partial \mathcal{F}}{\partial \mathbf{x}_0} $.</li>
  <li>
<strong>Visualize the gradients</strong>: You can either show the absolute values or highlight negative and positive contributions separately.</li>
</ul>

<h3 id="the-instructions-for-the-pytorch-code">The instructions for the PyTorch code:</h3>

<p>We have set the model in eval mode, but we can still catch the gradients of the input-image if ask PyTorch to do this and then do some backward calculation. That is what you need to do. So complete the procedure in order that:</p>
<ul>
  <li>Input should be preprocessed (and converted into a torch tensor).</li>
  <li>Set the <mark>required_gradient=True</mark> on the input tensor.</li>
  <li>Calculate the output (with previous method predict).</li>
  <li>Set the gradient to zero and do a backward on the output.</li>
  <li>Gradients w.r.t input can now be found under input.grad</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">calculate_outputs_and_gradients</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">target_label_idx</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="c1"># Calculates the gradient of the output w.r.t. the input image
</span>    <span class="c1"># The result should be a gradients numpy matrix of same dimensions as the inputs
</span>    <span class="n">predict_idx</span> <span class="o">=</span> <span class="bp">None</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>                             <span class="c1"># for every image
</span>        <span class="nb">input</span> <span class="o">=</span> <span class="nf">pre_processing</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span>  
        <span class="nb">input</span><span class="p">.</span><span class="n">requires_grad</span><span class="o">=</span><span class="bp">True</span>
        <span class="nf">print </span><span class="p">(</span><span class="n">target_label_idx</span><span class="p">)</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">target_label_idx</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span>
        <span class="c1"># clear grad
</span>        <span class="n">model</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="c1">## BEGIN student code
</span>        <span class="c1"># Perform a backward pass on the output and collect the gradient w.r.t. the input
</span>        <span class="c1"># Store this gradient in the variable 'gradient' 
</span>        <span class="n">output</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="nb">input</span><span class="p">.</span><span class="n">grad</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># do backward and gather gradients of input
</span>        <span class="c1">## END student code
</span>        <span class="n">gradients</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">gradient</span><span class="p">)</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">gradients</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">target_label_idx</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calculate the gradient and the label index
#gradients, label_index = calculate_outputs_and_gradients([img], model, None, cuda)    
</span><span class="n">gradients</span><span class="p">,</span> <span class="n">label_index</span> <span class="o">=</span> <span class="nf">calculate_outputs_and_gradients</span><span class="p">([</span><span class="n">img</span><span class="p">],</span> <span class="n">model</span><span class="p">,</span> <span class="n">target_label_idx</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>    
<span class="n">gradients</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">gradients</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

<span class="c1">#Note that if target_label_idx == None, the calculate_output)and_gradients function assume:
#            target_label_idx = torch.argmax(output, 1).item()
</span>
<span class="c1"># Please note that the dimensions of gradients are same as dimensions of input
</span><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">gradients</span><span class="sh">'</span><span class="p">,</span> <span class="n">gradients</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span> 
<span class="c1"># Please note that gradients are positive and negative values
</span><span class="nf">print</span><span class="p">(</span><span class="n">gradients</span><span class="p">[:</span><span class="mi">3</span><span class="p">,</span> <span class="p">:</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">label_index</span><span class="p">)</span>
</code></pre></div></div>

<font color="green"><b>ToDo 2</b></font>
<p>For your image with two animals, consider both IDâs as target_label_idx.</p>
<ul>
  <li>Run the classifier with each ID</li>
  <li>After running the forward pass, compute the gradients</li>
</ul>

<font color="blue"><b>ToThink 2</b></font>
<p>Are the gradients the same when you use different target classes? Why?</p>

<h3 id="visualize-the-gradients">Visualize the gradients</h3>

<p>Try to visualise the image and the saliency map.</p>

<p><strong>Tip:</strong> take absolute values of the gradients and maximize over all three channels.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="c1"># Retrieve the saliency map and also pick the maximum value from channels on each pixel.
# In this case, we look at dim=2. Recall the shape of gradients (width, height, channel)
</span>
<span class="k">def</span> <span class="nf">plot_gradients</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">title</span><span class="p">):</span>
  <span class="c1"># plots image (dimensions: Width X Heigth X 3) and gradients (dimensions: Width X Heigh x 3) - both numpy arrays
</span>  <span class="n">saliency</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">gradients</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>       <span class="c1"># takes maximum over 3 color channels                                                 
</span>  <span class="c1"># Visualize the image and the saliency map
</span>  <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">img</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">imshow</span><span class="p">(</span><span class="n">saliency</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="sh">'</span><span class="s">hot</span><span class="sh">'</span><span class="p">)</span>
  <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">tight_layout</span><span class="p">()</span>
  <span class="n">fig</span><span class="p">.</span><span class="nf">suptitle</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
  <span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

<span class="nf">plot_gradients</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="sh">'</span><span class="s">The Image and Its Saliency Map</span><span class="sh">'</span><span class="p">)</span>

</code></pre></div></div>

<font color="red"><b>ToSubmit 1</b></font>
<p>In your report, include your two images, the two saliency map, the two target  label, the predicted label and the likelihood your models assigns to each label. Add a caption explaining very briefly (1 or 2 sentences) whether thereâs a difference and why.</p>

<h3 id="issues-with-saliency-maps-and-vanilla-gradients-saturation">Issues with saliency maps and vanilla gradients (saturation)</h3>

<p>Vanilla Gradient methods, notoriously, are facing saturation problems, as explained in Avanti et al. (2017). When the ReLU is used, and when the activation goes below zero, then, the activation is limited at zero and does not change any more. Hence, the activation is saturated.</p>

<p>Therefore, multiple strategies have been proposed to deal with that issue. One of them is Gradient-weighted Class Activation Map (<em>Grad-Cam</em>) that instead of calculating the gradient to the input image it make use of the last convolutional layer.</p>

<h3 id="gradient-weighted-class-activation-mapping-grad-cam">Gradient-weighted Class Activation Mapping (Grad-CAM)</h3>

<h1 id="4-gradient-weighted-class-activation-mapping-grad-cam"><strong>4 Gradient-weighted Class Activation Mapping (Grad-Cam).</strong></h1>

<p>Unlike saliency maps, in the <strong>Grad-Cam</strong> approach the gradient is not backpropagated all the way back to the image, but (usually) to the last convolutional layer in order to generate a visualization map that highlights important regions of the input.</p>

<p>A naive visualization approach could be the following:</p>

<ul>
  <li>Simply employ the values for each feature map, (of the last convolutional layer),</li>
  <li>Then, average these feature maps and overlay this over our image (by rescaling back to initial size).</li>
</ul>

<p>However, while simple, it is not really helpful approach, since these maps encode information for all classes, while we are interested in a specific class. <strong>Grad-CAM</strong> needs to figure out the importance for each of the $k$ feature map $A_k \in \mathbb{R}^{w \times h}$ ($w$ the width and $h$ the height of the features maps) in respect to our class $c$ of interest.</p>

<p>We have to weight each pixel of each feature map with the gradient before averaging over the feature maps $A_k$. This heatmap is send through the ReLU function which set all negative values to zero. The reason for that is that we are only interested in the parts that contribute to the selected class $c$ and not to other classes. The final feature map is rescaled back to the original image size. We then overlay it over the original image for producing the final visualization.</p>

<p><strong>Grad Cam recipe:</strong></p>

<ul>
  <li>Forward-propagate the input image $\mathbf{x}_0$ through the convolutional VGG19 network by calculating the $\mathcal{F}(\mathbf{x}_0)$.</li>
  <li>Obtain the score for the class of interest, that means the activation before the softmax layer.</li>
  <li>All the rest classesâ activations should be set to zero.</li>
  <li>Back-propagate the gradient of the class of interest to the last convolutional layer before the fully connected layers:</li>
</ul>

\[\frac{\partial y_{c}}{\partial A^k}\]

<ul>
  <li>Weight each feature map âpixelâ by the gradient for the class. Indices $i$ and $j$ refer to the width and height dimensions:</li>
</ul>

\[\alpha^{c}_{k} = \overbrace{\frac{1}{Z} \sum_i \sum_j}^{\text{global averaging pooling}} \underbrace{\frac{\partial y_{c}}{\partial A^{k}_{ij}}}_{\text{gradients of the backpropagation}}\]

<p>This means that the gradients are globally pooled.</p>

<ul>
  <li>Calculate an average of the feature maps, weighted per pixel by backpropagated gradient.</li>
  <li>Apply ReLU to the averaged feature map.</li>
</ul>

\[L_{ij}^c = ReLU \sum_k \alpha^{c}_{k} A^{k}_{ij}\]

<p>We now have a heatmap $L^c$ for the class $c$.</p>

<ul>
  <li>Regarding the visualization: Scale values of the $L^c$ to the interval between 0 and 1. Upscale the image and overlay it over the original image.</li>
</ul>

<p>In our classification example this approach uses the activation map of the final convolutional layer (with VGG: the final features layer). Note that such an Activation Map can be a block of $14 \times 14 \times 512$, where the $14 \times 14$ indicated a grid on the image (noted by subscripts i and j) and the 512 is the number of channels (features, noted by the letter k). <strong>Grad Cam</strong> pools the Activation Map over the channels, and it gives a weight equal to the contribution of each channel to the prediction. This contribution of each channel is calculated by taking the gradient of the output w.r.t. the Activation Map and then pool this over the spacial ($14\times14$) dimensions.</p>

<p>For the calculation of the gradient w.r.t the Activation Map we need a little PyTorch trick since this gradient cannot be accessed by default. The PyTorch trick is called a âhookâ. We can register a hook on a tensor of the network. With a hook we can define a little program that is executed when the tensor is touched during a backward pass. In our case we register a hook on the Activation Map we want to study and that is the 36th layer of the VGG19 convolutional âfeaturesâ layer. The hook needs to be registered during a forward pass, so we will redefine the forward pass for our model.</p>

<p>There is a nice youtube tutorial on pytorch and hooks https://www.youtube.com/watch?v=syLFCVYua6Q. (22 minutes but I think it is worth it)</p>

<h3 id="define-a-new-vgg-model-including-a-hook">Define a new VGG model including a hook</h3>

<p>The VGG() class is based on the pretrained models.vgg19 that we know now.</p>

<p>In the init, the Activation Map we want to study is defined. That is the output of the first 36 feature layers.</p>

<p>In the activations_hook method we define our hook that will store the gradient calculated on the tensor in self.gradients.</p>

<p>In the forward we execute all VGG layers âby handâ. The hook is registered on the output of the first 36 feature layers. And then the remaining layers are defined.</p>

<p>When defined, we load this model, move it to our GPU if available and put the model in eval mode.</p>

<h3 id="activity">Activity:</h3>
<p>Finish the code below by finishing the method get_activations_gradient.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">VGG</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="c1"># VGG class builds on vgg19 class. The extra feature is the registration of a hook, that
</span>    <span class="c1"># stores the gradient on the last convolutional vgg layer (vgg.features[:36] in self.gradient)
</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">(</span><span class="n">VGG</span><span class="p">,</span> <span class="n">self</span><span class="p">).</span><span class="nf">__init__</span><span class="p">()</span>
        
        <span class="c1"># get the pretrained VGG19 network
</span>        <span class="n">self</span><span class="p">.</span><span class="n">vgg</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="nf">vgg19</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="c1"># self.vgg = model
</span>
        <span class="c1"># disect the network to access its last convolutional layer
</span>        <span class="n">self</span><span class="p">.</span><span class="n">features_conv</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">vgg</span><span class="p">.</span><span class="n">features</span><span class="p">[:</span><span class="mi">36</span><span class="p">]</span>
        
        <span class="c1"># get the max pool of the features stem
</span>        <span class="n">self</span><span class="p">.</span><span class="n">max_pool</span> <span class="o">=</span> <span class="n">nn</span><span class="p">.</span><span class="nc">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        
        <span class="c1"># get the classifier of the vgg19
</span>        <span class="n">self</span><span class="p">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">vgg</span><span class="p">.</span><span class="n">classifier</span>
        
        <span class="c1"># placeholder for the gradients
</span>        <span class="n">self</span><span class="p">.</span><span class="n">gradients</span> <span class="o">=</span> <span class="bp">None</span>
    
    <span class="c1"># hook for the gradients of the activations: it stores the calculated grad (on our tensor) in self.gradients.
</span>    <span class="k">def</span> <span class="nf">activations_hook</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">grad</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">gradients</span> <span class="o">=</span> <span class="n">grad</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># gives the output of the first 36 'feature' layers
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">features_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        
        <span class="c1"># register the hook (note: h is a handle, giving the hook a identifier, we do not use it here)
</span>        <span class="n">h</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">register_hook</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">activations_hook</span><span class="p">)</span>

        <span class="c1"># apply the remaining pooling
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">max_pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">view</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># apply the remaining classifying
</span>        <span class="n">x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x</span>

    <span class="c1"># method for the gradient extraction
</span>    <span class="k">def</span> <span class="nf">get_activations_gradient</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1">## Should return the gradients of the output with respect to the last convolutional layer
</span>        <span class="c1">## BEGIN Students TODO
</span>        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">gradients</span>
        <span class="c1">## END students TODO
</span>    
    <span class="c1"># method for the activation exctraction
</span>    <span class="k">def</span> <span class="nf">get_activations</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">features_conv</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>    

<span class="n">vgg</span> <span class="o">=</span> <span class="nc">VGG</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda:</span><span class="sh">'</span><span class="p">,</span> <span class="n">cuda</span><span class="p">,</span> <span class="sh">'</span><span class="s">device:</span><span class="sh">'</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">vgg</span> <span class="o">=</span> <span class="n">vgg</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">vgg</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
</code></pre></div></div>

<p>Now calculate the gradients of a prediction w.r.t. the activation map.**</p>

<p>For that we do a prediction with our newly defined model vgg, and perform a backward on the output (the logit of the prediction vector that is largest). After the backward, the gradients w.r.t the activation map are stored in self.gradient:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># get the most likely prediction of the model
</span>
<span class="nb">input</span> <span class="o">=</span> <span class="nf">pre_processing</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span>          <span class="c1"># preprocess: image (normalise, transpose, make tensor on cuda, requires_grad=True)
</span><span class="nf">print</span><span class="p">(</span><span class="nb">input</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">pred</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">vgg</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span>                         
<span class="nf">print</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>                        

<span class="c1"># also with our newly created VGG(), you should find a correct class (2=shark, 385/386 = elephants)
</span></code></pre></div></div>
<p>And finally:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">output</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># pull the gradients out of the model
</span><span class="n">gradients</span> <span class="o">=</span> <span class="n">vgg</span><span class="p">.</span><span class="nf">get_activations_gradient</span><span class="p">()</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">gradients:</span><span class="sh">'</span><span class="p">,</span> <span class="n">gradients</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># pool the gradients across the channels
</span><span class="n">pooled_gradients</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">pooled gradients:</span><span class="sh">'</span><span class="p">,</span> <span class="n">pooled_gradients</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># get the activations of the last convolutional layer
</span><span class="n">activations</span> <span class="o">=</span> <span class="n">vgg</span><span class="p">.</span><span class="nf">get_activations</span><span class="p">(</span><span class="nb">input</span><span class="p">).</span><span class="nf">detach</span><span class="p">()</span>

<span class="c1"># weight the channels by corresponding gradients
</span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">512</span><span class="p">):</span>
    <span class="n">activations</span><span class="p">[:,</span> <span class="n">i</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span> <span class="o">*=</span> <span class="n">pooled_gradients</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
    
<span class="c1"># average the channels of the activations
</span><span class="n">heatmap</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">activations</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="nf">squeeze</span><span class="p">()</span>

<span class="c1"># relu on top of the heatmap
# expression (2) in https://arxiv.org/pdf/1610.02391.pdf
# heatmap = np.maximum(heatmap, 0)
</span><span class="n">heatmap</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">maximum</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>

<span class="c1"># normalize the heatmap
</span><span class="n">heatmap</span> <span class="o">/=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">heatmap</span><span class="p">)</span>
<span class="c1"># END students TODO
</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">heatmap:</span><span class="sh">'</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># draw the heatmap
</span><span class="n">heatmap</span> <span class="o">=</span> <span class="n">heatmap</span><span class="p">.</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">squeeze</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">matshow</span><span class="p">(</span><span class="n">heatmap</span><span class="p">)</span>
</code></pre></div></div>

<font color="green"><b>ToDo 3</b></font>
<p>For your image with 2 animals and each of the two target categories:</p>
<ul>
  <li>Perform the forward pass again, but now with our adapted VGG model</li>
  <li>Draw the Grad-CAM heatmaps $L^c$.</li>
</ul>

<p>Code snippet that might be useful:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gradients, label_index = calculate_outputs_and_gradients([img], vgg, target_label_idx=None, cuda=True)    
gradients = np.transpose(gradients[0], (1, 2, 0))
</code></pre></div></div>

<h3 id="overlaying-heatmaps-and-iamges">Overlaying heatmaps and iamges:</h3>
<p>Now we have the heatmap, we can overlay it on the original image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># draw the image
</span><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">img:</span><span class="sh">'</span><span class="p">,</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">matshow</span><span class="p">(</span><span class="n">img</span><span class="o">/</span><span class="mi">255</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">print</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">heatmap</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">heatmap</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">uint8</span><span class="p">(</span><span class="mi">255</span> <span class="o">*</span> <span class="n">heatmap</span><span class="p">)</span>
<span class="n">heatmap</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">applyColorMap</span><span class="p">(</span><span class="n">heatmap</span><span class="p">,</span> <span class="n">cv2</span><span class="p">.</span><span class="n">COLORMAP_JET</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">img</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">img</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>
<span class="nf">print</span><span class="p">(</span><span class="n">heatmap</span><span class="p">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">heatmap</span><span class="p">.</span><span class="nf">min</span><span class="p">(),</span> <span class="n">heatmap</span><span class="p">.</span><span class="nf">max</span><span class="p">())</span>

<span class="n">super_img</span> <span class="o">=</span> <span class="n">heatmap</span> <span class="o">*</span> <span class="mf">0.4</span> <span class="o">+</span> <span class="n">img</span> <span class="o">*</span> <span class="mf">0.6</span>
<span class="n">super_img</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">uint8</span><span class="p">(</span><span class="n">super_img</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">matshow</span><span class="p">(</span><span class="n">super_img</span><span class="p">)</span>
</code></pre></div></div>

<font color="red"><b>ToSubmit 2</b></font>
<p>In your report, include the two Grad-CAM heatmaps for the image with two animals. Add a caption explaining very briefly (1 or 2 sentences) whether thereâs a difference and why.</p>

<h3 id="path-integration-methods---integrated-gradients-ig">Path-integration methods - Integrated Gradients (IG)</h3>

<p>As a reminder, the problem that want to study in this tutorial is to find a way to attribute importance in the input features of the vector $\mathbf{x}_i \in \mathbb{R}^{D}$ given the result of the classification from a classifier $\mathcal{F}$.</p>

<p>Suppose that we have a funtion $\mathcal{F}: \mathbb{R}^{D} \to [0, 0, â¦ , 1, â¦ , 0, 0] \in \mathbb{R}^{M} $ which represent a neural network. The input to this network are data $\mathbf{X} = (\mathbf{x}_1, \mathbf{x}_2, â¦, \mathbf{x}_n) \in \mathbb{R}^{N\times D}$ we would like to calculate a vector $\mathbf{\alpha}_0 = (\alpha_1, \alpha_2, â¦, \alpha_D) \in \mathbb{R}^{D}$ which is the contribution of the input vector $\mathbf{x}_0$ to the prediction $\mathcal{F}(\mathbf{x}_i)$.</p>

<p>Path-attribution methods in contrast with the gradient methods that we have mentioned before (saliency maps and grad-cam) compare the current image  $\mathbf{x}$ to a reference image $\mathbf{x}^{\prime}$ which can be for instance a black image (or a white image or an image containing random noise). The difference in actual and baseline prediction is divided among the pixels.</p>

<h3 id="ig-approach">IG approach</h3>

<p>As a reminder, the problem that want to study in this tutorial is to find a way to attribute importance in the input features of the vector $\mathbf{x}_i \in \mathbb{R}^{D}$ given the result of the classification from a classifier $\mathcal{F}$.</p>

<p>Suppose that we have a funtion $\mathcal{F}: \mathbb{R}^{D} \to [0, 0, â¦ , 1, â¦ , 0, 0] \in \mathbb{R}^{M} $ which represent a neural network. The input to this network are data $\mathbf{X} = (\mathbf{x}_1, \mathbf{x}_2, â¦, \mathbf{x}_n) \in \mathbb{R}^{N\times D}$ we would like to calculate a vector $\mathbf{\alpha}_0 = (\alpha_1, \alpha_2, â¦, \alpha_D) \in \mathbb{R}^{D}$ which is the contribution of the input vector $\mathbf{x}_0$ to the prediction $\mathcal{F}(\mathbf{x}_i)$.</p>

<p>Path-attribution methods in contrast with the gradient methods that we have mentioned before (saliency maps and grad-cam) compare the current image  $\mathbf{x}$ to a reference image $\mathbf{x}^{\prime}$ which can be for instance a black image (or a white image or an image containing random noise). The difference in actual and baseline prediction is divided among the pixels.</p>

<h3 id="calculate-the-integrated-gradients-with-pytorch-recipe">Calculate the integrated gradients with PyTorch recipe.</h3>

<p>Recipe for calculating the IG in our example:</p>
<ul>
  <li>
<strong>Choose a baseline image</strong>. You can make use of a black/white or an white noise image.</li>
  <li>
<strong>Build a series of inputs</strong>, each input consist of the baseline plus an additional fraction of the input-image. The final input is the baseline plus the full image. Choose your fraction at 20.</li>
  <li>For each of these inputs, <strong>calculate the gradients of the input</strong> w.r.t. the prediction (using methods under 2 above). Take the average of all these gradients.</li>
  <li>
<strong>Calculate the difference of image and baseline</strong>: I-B. And calculate Integrated Gradient = (I-B)*average of gradients.</li>
  <li>If you have chosen for another baseline, e.g. for a uniform random generated baseline, then perform this procedure for multiple samples.</li>
</ul>

<h4 id="integrated-gradients-with-one-baseline">Integrated Gradients with one baseline</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># integrated gradients
</span><span class="k">def</span> <span class="nf">integrated_gradients</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">target_label_idx</span><span class="p">,</span> <span class="n">baseline</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="c1"># determine baseline
</span>    <span class="k">if</span> <span class="n">baseline</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
        <span class="n">baseline</span> <span class="o">=</span> <span class="mi">0</span> <span class="o">*</span> <span class="n">inputs</span> 
    <span class="c1"># scale inputs and compute gradients
</span>    <span class="n">scaled_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">baseline</span> <span class="o">+</span> <span class="p">(</span><span class="nf">float</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">/</span> <span class="n">steps</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">inputs</span> <span class="o">-</span> <span class="n">baseline</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
    <span class="n">grads</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="nf">calculate_outputs_and_gradients</span><span class="p">(</span><span class="n">scaled_inputs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">target_label_idx</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span>

   <span class="c1"># BEGIN students TODO
</span>    <span class="n">avg_grads</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">average</span><span class="p">(</span><span class="n">grads</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>      <span class="c1"># why 51 steps and then remove final result ?
</span>    <span class="n">avg_grads</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">avg_grads</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">delta_X</span> <span class="o">=</span> <span class="p">(</span><span class="nf">pre_processing</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span> <span class="o">-</span> <span class="nf">pre_processing</span><span class="p">(</span><span class="n">baseline</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)).</span><span class="nf">detach</span><span class="p">().</span><span class="nf">squeeze</span><span class="p">(</span><span class="mi">0</span><span class="p">).</span><span class="nf">cpu</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
    <span class="n">delta_X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">delta_X</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">integrated_grad</span> <span class="o">=</span> <span class="n">delta_X</span> <span class="o">*</span> <span class="n">avg_grads</span>
    <span class="c1"># END students TODO
</span>    <span class="k">return</span> <span class="n">integrated_grad</span>
</code></pre></div></div>

<h4 id="integrated-gradients-with-a-sample-of-random-baselines">Integrated Gradients with a sample of random baselines</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">random_baseline_integrated_gradients</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">target_label_idx</span><span class="p">,</span> <span class="n">steps</span><span class="p">,</span> <span class="n">num_random_trials</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="c1"># when baseline randomly generated, take some samples and average result
</span>    <span class="c1"># BEGIN students TODO
</span>    <span class="n">all_intgrads</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">random_baseline</span> <span class="o">=</span> <span class="mf">255.0</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">random</span><span class="p">(</span><span class="n">inputs</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">num_random_trials</span><span class="p">):</span>
        <span class="n">integrated_grad</span> <span class="o">=</span> <span class="nf">integrated_gradients</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">target_label_idx</span><span class="p">,</span> <span class="n">baseline</span><span class="o">=</span><span class="n">random_baseline</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="n">steps</span><span class="p">,</span> <span class="n">cuda</span><span class="o">=</span><span class="n">cuda</span><span class="p">)</span>
        <span class="n">all_intgrads</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">integrated_grad</span><span class="p">)</span>
        <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">the trial number is: {}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="n">avg_intgrads</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">average</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">all_intgrads</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="c1"># END students TODO
</span>    <span class="k">return</span> <span class="n">avg_intgrads</span>
</code></pre></div></div>

<font color="green"><b>ToDo 4</b></font>
<p>Investigate how well integrated gradients can determine what parts of the image your models is looking at for different target categories. Also investigate whether the zero baseline or a sample of random baselines gives you clearer feature attributions.</p>

<p>Code snippets that might be useful:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># calculate the integrated gradients 
print('img:', img.shape, 'label_index', label_index)

# for zero baseline
int_gradients_zerobl = integrated_gradients(img, model, label_index, baseline=None, steps=50, cuda=cuda)
print('DONE')
# for random baselines, we average over number of trials
int_gradients_randombl = random_baseline_integrated_gradients(img, model, label_index, steps=50, num_random_trials=5, cuda=cuda)    
print('DONE')

# calculate saliency
gradients, _ = calculate_outputs_and_gradients([img], model, None, cuda) 
gradients = np.transpose(gradients[0], (1, 2, 0))

# combine it all in one image
plot_gradients(img, gradients, 'The Image and Its Saliency Map')
plot_gradients(img, int_gradients_zerobl, 'Image and Integrated Gradients with Zero Baseline')
plot_gradients(img, int_gradients_randombl, 'Image and Integrated Gradients with sample of Random Baselines')
</code></pre></div></div>

<font color="red"><b>ToSubmit 3</b></font>

<p>Include in your  Workshop-0 report two images  with results applying  integrated gradients illustrating the strongest differences you have found (i.e., manipulating target categories, baselines, number of samples, or number of steps along the integration path). Include a brief caption that describes the experiment and your interpretation.</p>

<h2 id="lime">LIME</h2>

<p><a href="../../2022/LIME/">LIME tutorial</a></p>

<h2 id="conclusion">Conclusion</h2>

<p>In this post, we have seen two ways of using language for RL. There have been a lot of other ways recently in this direction. Some examples of these are</p>

<ul>
  <li>
    <d-cite key="lampinen-icml22a"></d-cite>
    <p>augment policy networks with the auxiliary target of generating explanations and use this to learn the relational and causal structure of the world</p>
  </li>
  <li>
    <d-cite key="kumar-neurips22a"></d-cite>
    <p>use language to model compositional task distributions and induce human-centric priors into RL agents.</p>
  </li>
</ul>

<p>Given the growth of pre-trained language models, it is only a matter of time before we see many more innovative ideas come around in this field. Language, after all, is a powerful tool to incorporate structural biases into RL pipelines. Additionally, language opens up the possibility of easier interfaces between humans and RL agents, thus, allowing more human-in-the-loop methods to be applied to RL. Finally, the symbolic nature of natural language allows better interpretability in the learned policies, while potentially making them more explainable. Thus, I see this as a very promising direction of future research</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/kristosh/assets/bibliography/2023-05-14-Posthoc-XAI.bib"></d-bibliography>
</div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2023 Christos  Athanasiadis. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>.

      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
