<!DOCTYPE html>
<!-- _layouts/distill.html --><html>
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Why should I trust you? Local Interpretable Model-agnostic Explanations | Christos  Athanasiadis</title>
    <meta name="author" content="Christos  Athanasiadis">
    <meta name="description" content="This page's goal is to present a PostHoc feature attribution XAI methodology called LIME (Local Interpretable Model-agnostic Explanations) and demonstrate how it can be used to explain image classification tasks. You will be guided through the code and the results of the LIME algorithm. Part of this workshop will be some research questions that need to be answered by you. These questions can be found in the last part of the tutorials and you will encounter these questions with the &lt;mark&gt;TOSUBMIT&lt;/mark&gt; tag. You will need to submit your answers to these questions in the form of a .pdf file on Canvas. The deadline for submitting your answers is the .. of June 2023.">


    <link rel="stylesheet" href="/assets/css/codeblock.scss">
    <link rel="stylesheet" href="/assets/css/codeblock.scss">

    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/.css" media="" id="highlight_theme_light">



    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%98%8E&lt;/text&gt;&lt;/svg&gt;">
    
    

    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://kristosh.github.io//blog/2023/LIME/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

    <link rel="stylesheet" href="/assets/css/codeblock.scss">

    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
  </head>

  <body>
<d-front-matter>
    <script async type="text/json">{
      "title": "Why should I trust you? Local Interpretable Model-agnostic Explanations",
      "description": "This page's goal is to present a PostHoc feature attribution XAI methodology called LIME (Local Interpretable Model-agnostic Explanations) and demonstrate how it can be used to explain image classification tasks. You will be guided through the code and the results of the LIME algorithm. Part of this workshop will be some research questions that need to be answered by you. These questions can be found in the last part of the tutorials and you will encounter these questions with the <mark>TOSUBMIT</mark> tag. You will need to submit your answers to these questions in the form of a .pdf file on Canvas. The deadline for submitting your answers is the .. of June 2023.",
      "published": "May 13, 2023",
      "authors": [
        {
          "author": "Christos Athanasiadis",
          "authorURL": "https://www.linkedin.com/in/christos-athanasiadis-a3b51035/",
          "affiliations": [
            {
              "name": "UvA, Interpretability and Explainability in AI",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">ChristosÂ </span>Athanasiadis</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>Why should I trust you? Local Interpretable Model-agnostic Explanations</h1>
        <p>This page's goal is to present a PostHoc feature attribution XAI methodology called LIME (Local Interpretable Model-agnostic Explanations) and demonstrate how it can be used to explain image classification tasks. You will be guided through the code and the results of the LIME algorithm. Part of this workshop will be some research questions that need to be answered by you. These questions can be found in the last part of the tutorials and you will encounter these questions with the <mark>TOSUBMIT</mark> tag. You will need to submit your answers to these questions in the form of a .pdf file on Canvas. The deadline for submitting your answers is the .. of June 2023.</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#local-interpretable-model-agnostic-explanations">Local Interpretable Model-agnostic Explanations</a></div>
            <ul>
              <li><a href="#interpretable-representations">Interpretable Representations</a></li>
              <li><a href="#lime-approach-details">LIME approach details</a></li>
              <li><a href="#code-implementation">Code implementation</a></li>
              <li><a href="#lime-explanation">LIME explanation</a></li>
              <li><a href="#creating-perturbations-of-image">Creating Perturbations of image</a></li>
              
            </ul>
<div><a href="#results">Results</a></div>
            <div><a href="#adversarial-attacks">Adversarial attacks</a></div>
            <div><a href="#tosubmit">TOSUBMIT</a></div>
            <div><a href="#conclusions">Conclusions</a></div>
            <div><a href="#references">References</a></div>
            
          </nav>
        </d-contents>

        <h1 id="local-interpretable-model-agnostic-explanations">Local Interpretable Model-agnostic Explanations</h1>

<center>
<video autoplay="" muted="" loop="" controls="" src="https://kristosh.github.io//assets/video/2023-05-13-LIME/caretta.mp4" style="width:600px" type="video/mp4">
</video>
<figcaption>A demonstration of the whole LIME algorithm.</figcaption>
</center>

<p>In this post, we will study how
<mark style="background-color:LavenderBlush;">LIME</mark> (Local
Interpretable Model-agnostic Explanations) ([1]) generates
explanations for image classification tasks. The basic idea is to
understand why a machine learning model predicts that a specific image
belongs to a certain class (<em>caretta</em> our visual example).
Briefly, this technique constructs a <em>new</em> simple model (for
example a <mark style="background-color:LavenderBlush;"><em>linear
classifier</em></mark>) which is easy to be interpreted by humans and at the same time approximates
the predictions of the <em>black-box</em> model in the neighborhood
around the instance that needs to be explained (<em>local faithfulness
</em>).</p>

<p>The <mark style="background-color:LavenderBlush;">LIME</mark> explainer is <em>model-agnostic</em> which means is not
restricted to a specific model and can be used to explain any
<mark>black-box</mark> classifier. So we donâ€™t need to have access to
the details of our model (input, intermediate layers etc) to generate
explanations. Moreover, the explainer is <em>local</em> meaning that it
explains the prediction of the model in the neighborhood of the instance
being explained. This technique lies in the PostHoc category of XAI
methods, meaning that it explains the model after it has been trained.</p>

<h2 id="interpretable-representations">Interpretable Representations</h2>

<p>An interpretable explanation in an image classifier explainer should use
a representation that is understandable to humans, by explaining which
parts of the input image influence the model decision. For instance, the
pixel-based representations are not very informative especially when we
deal with huge images and therefore a better way to explain the model
decision is to use
<a href="https://infoscience.epfl.ch/record/149300" rel="external nofollow noopener" target="_blank">super-pixels</a> ([3]). Super-pixels
are groups of pixels that share similar characteristics such as color
and texture. Hence, a possible interpretable representation for image
classification may be a binary vector indicating the <em>presence</em>
or <em>absence</em> of a super-pixel.</p>

<p>Thus, our explainer needs to find a way to attribute importance to each
super-pixel in the initial input image. Itâ€™s important to note here,
that the interpretable representations are meant to be just for the
<mark style="background-color:LightCyan;">LIME</mark> explainer while the <em>black-box</em> can still be trained using the
original pixel-based representations.</p>

<p><mark style="background-color:LightCyan;">LIME</mark> approach aims to
just explain why the classifier took a specific decision upon a specific
input image. It does not aim to explain the whole model. Authors, in the
paper, proposed a mechanism called
<mark style="background-color:LightCyan;">SP-LIME</mark> that aims to
explain the whole model. While we will not touch this method in this
tutorial we encourage you to have a look at it in the original paper.An interpretable explanation in an image classifier explainer should use
a representation that is understandable to humans, by explaining which
parts of the input image influence the model decision. For instance, the
pixel-based representations are not very informative especially when we
deal with huge images and therefore a better way to explain the model
decision is to use
<a href="https://infoscience.epfl.ch/record/149300" rel="external nofollow noopener" target="_blank">super-pixels</a> ([3]). Super-pixels
are groups of pixels that share similar characteristics such as color
and texture. Hence, a possible interpretable representation for image
classification may be a binary vector indicating the <em>presence</em>
or <em>absence</em> of a super-pixel.</p>

<p>Thus, our explainer needs to find a way to attribute importance to each
super-pixel in the initial input image. Itâ€™s important to note here,
that the interpretable representations are meant to be just for the
<mark style="background-color:LightCyan;">LIME</mark> explainer while the <em>black-box</em> can still be trained using the
original pixel-based representations.</p>

<p><mark style="background-color:LightCyan;">LIME</mark> approach aims to
just explain why the classifier took a specific decision upon a specific
input image. It does not aim to explain the whole model. Authors, in the
paper, proposed a mechanism called
<mark style="background-color:LightCyan;">SP-LIME</mark> that aims to
explain the whole model. While we will not touch this method in this
tutorial we encourage you to have a look at it in the original paper.</p>

<h2 id="lime-approach-details">LIME approach details</h2>

<p>To explain how <mark style="background-color:LavenderBlush;">LIME</mark> works in detail we should introduce some definitions and maths
ðŸ˜Ž.</p>

<p>Hence, let $\mathbf{x} \in R^{d}$ denote the original vector
representation of an instance being explained (in our case a vector with
all pixels in the image), and we use $\mathbf{x}^{\prime} \in {0, 1}^d$ to denote a
binary vector for its interpretable representation (super-pixels).</p>

<p>The <mark style="background-color:LavenderBlush;">LIME</mark> explainer is defined as (or explanation model) $g \in G$, where $G$
is a class of potentially interpretable models, such as <em>linear
models</em>, <em>decision trees</em> etc. To keep things simple, in this
tutorial, we will consider just <em>linear classifiers</em>. As not
every $g \in G$ may be simple enough to be interpretable $\Omega(g)$ is
defined as a measure of complexity (in juxtaposition with the
interpretability) of the explanation $g \in G$. For example, for
decision trees $\Omega(g)$ may be the depth of the tree, while for
linear models, $\Omega(g)$ may be the number of non-zero weights. We
define as $f: R^{d} \to R$ the <em>black-box</em> model that we would
like to explain. In classification, $f(\mathbf{x})$ is the probability
(or a binary indicator) that $\mathbf{x}$ belongs to a certain class.</p>

<p>We further use $\pi_{\mathbf{x}}(\mathbf{z})$ as a proximity measure
between an instance $\mathbf{z}$ to $\mathbf{x}$, so as to define
locality around $\mathbf{x}$. Finally, let
$\mathcal{L}(f, g, \pi_{\mathbf{x}})$ be a measure of how unfaithful $g$
is in approximating $f$ in the locality defined by $\pi_{\mathbf{x}}$.
To ensure both <em>interpretability</em> and <em>local fidelity</em>,
they must minimize $L(f, g, \pi_{x})$ while having $\Omega(g)$ be as low
as possible. This will keep the complexity of the explanation low while
maintaining the fidelity of the explanation high.</p>

<p>Hence, the loss function for the <mark style="background-color:LavenderBlush;">LIME</mark> explainer is the following equation:</p>

\[\xi(\mathbf{x}) = \mathcal{L}(f, g, \pi_{\mathbf{x}}) + \Omega(g)\]

<p>The above equation contains the tradeoff between <em>local fidelity</em>
which is expressed by $L$ and the <em>complexity</em> of the explainer that it is expressed
by $\Omega$.</p>

<p>The first term $\mathcal{L}(f, g, \pi_{\mathbf{x}})$ in the equation is represented by the weighted square loss:</p>

\[\mathcal{L}(f, g, \pi_{\mathbf{x}}) = \sum_{\mathbf{z}, \mathbf{z}^{'}}\pi_{\mathbf{x}}(\mathbf{z})(f(\mathbf{z})- g(\mathbf{z}^{'}))^{2}\]

<p>with $\pi_{\mathbf{x}}$ to be a kernel function that measures the proximity of $z$ to $x$:</p>

\[\pi_{\mathbf{x}} =  \exp(-D(\mathbf{x},\mathbf{z})^{2}/\sigma*{2})\]

<p>The idea is that by tuning the weights $\mathbf{w}$ we can use them
directly as a feature attribution to each super-pixel. The higher the
weight that corresponds to a specific super-pixel the more important
this super-pixel is for the prediction of the <em>black-box</em> model
and vice-versa.</p>

<p>Itâ€™s important to remind you here of the terms <em>faithfulness</em>
and <em>local fidelity</em> which are about how well our explainer
$g$ can approximate the decision of the <em>black-box</em> model $f$ in
the locality defined by $\pi_{\mathbf{x}}$.</p>

<p>The whole <mark style="background-color:LavenderBlush;">LIME</mark> algorithm can be summarized as follows:</p>

<figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2023-05-13-LIME/algorithm.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

<p>The <mark style="background-color:LavenderBlush;">kernel</mark> shows the proximity between the instance that we desire to explain and the
generated samples in the neighborhood. The neighborhood is created by
<mark style="background-color:LightCyan;">sampling</mark> instances
around the initial image. The sampling is done by perturbing
the instance being explained. For example, in the case of images, we can
perturb the image by zeroing out some super-pixels. The perturbed
instances are then fed to the <em>black-box</em> model and the output is
used to train the explainer. The weights of the interpretable model are
then used to explain the prediction of the <em>black-box</em> model.
Finally, in the algorithm,
<mark style="background-color:Lavender;">K-lasso</mark> refers to the
regularization that is introduced in a previous equation and relates to
the term $\Omega(g)$.</p>

<center>
<video autoplay="" muted="" loop="" controls="" src="https://kristosh.github.io//assets/video/2023-05-13-LIME/LIME3.mp4" style="width:600px" type="video/mp4">
</video>
<figcaption>A demonstration of the whole LIME algorithm.</figcaption>
</center>

<p>The above video explains the whole <mark style="background-color:LavenderBlush;">LIME</mark> process. The initial surface
represents the <mark style="background-color:Lavender;">black-box</mark>
classifier and the regions for the class of interest
(e.g.Â Caretta-caretta with the light-pink color). The dark red-colored
dot denotes the sample that we would like to explain and it is an image
with the label <em> Caretta-caretta</em>. The first step is to sample
the neighborhood of the point $\mathbf{x}$ that we would like to
explain. Several points are generated. The size of each generated sample
and the transparency relates to the distance from the initial point
$\mathbf{x}$ which is calculated based using
$\pi_{\mathbf{x}}(\mathbf{z})$. The next step is to apply the
<mark style="background-color:Lavender;">black-box</mark> classifier
$f()$ to find the label for each generated point. Samples with red
represent the class Caretta-caretta while samples with purple represent
the adversary class (not Caretta-caretta ;). The next step is to train the
interpretable model $g()$ using the generated samples. The weights of
the interpretable model are used to explain the prediction of the
<mark style="background-color:Lavender;">black-box</mark> classifier.</p>

<h2 id="code-implementation">Code implementation</h2>

<p>Firstly, we will need to import the required libraries. The code is written in Python 3.6.9 and PyTorch 1.7.0. You can access the code in google colab using the following <a href="TBA">link</a>. Firstly, you should run the following command to install the necessary libraries:</p>

<pre><code class="language-ptyhon">conda env create -f my_lime.yml
conda activate my_lime
</code></pre>

<h3 id="imports">Imports</h3>

<p>Now, having installed the necessary libraries we can import them. Throughout the whole tutorial, we will make use of The following libraries are used:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td>
<td class="rouge-code"><pre><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="n">torch.nn</span> <span class="k">as</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">os</span><span class="p">,</span> <span class="n">json</span>
<span class="kn">import</span> <span class="n">cv2</span>

<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">torchvision</span> <span class="kn">import</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">from</span> <span class="n">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">import</span> <span class="n">torch.nn.functional</span> <span class="k">as</span> <span class="n">F</span>
<span class="kn">import</span> <span class="n">copy</span>

<span class="kn">import</span> <span class="n">sklearn</span>
<span class="kn">import</span> <span class="n">sklearn.metrics</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<h3 id="initialization-of-a-pre-trained-vgg19-model">Initialization of a pre-trained VGG19 model</h3>
<p>The very first thing that we will do is load a pre-trained VGG19 model. This model will be used to classify images and we will try to explain
its behavior. The output of the model is a vector of 1000 probabilities
belonging to each class from the ImageNet dataset. The model is
initialized and the weights are loaded. The model is set to evaluation
mode. The model is set to run on GPU if available. You can do that on
Google colab by enabling the GPU option. The steps for that are the
following: <mark>Edit -\&gt; Notebook settings -\&gt; Hardware accelerator -\&gt;
GPU</mark>. The code for all these steps is the following:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td>
<td class="rouge-code"><pre><span class="c1"># load model
# model_type = 'vgg19'
</span><span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="p">.</span><span class="nf">vgg19</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c1"># run it on a GPU if available:
</span><span class="n">cuda</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">"</span><span class="s">cuda:0</span><span class="sh">"</span> <span class="k">if</span> <span class="n">torch</span><span class="p">.</span><span class="n">cuda</span><span class="p">.</span><span class="nf">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="sh">"</span><span class="s">cpu</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda:</span><span class="sh">'</span><span class="p">,</span> <span class="n">cuda</span><span class="p">,</span> <span class="sh">'</span><span class="s">device:</span><span class="sh">'</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="c1"># set model to evaluation
</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>Ignore for now the warnings! This code should return the architecture of
the VGG19 model. Of course, feel free to choose the model of your choice
(the code should work with any model). Now letâ€™s load and process the
image (for the VGG19 classifier) that we would like to test our
<mark style="background-color:Lavender;">LIME</mark> explainer. You can
freely choose the image that you would like to explain.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td>
<td class="rouge-code"><pre><span class="k">def</span> <span class="nf">imread_img</span><span class="p">(</span><span class="n">file_name</span><span class="p">):</span>
  
  <span class="c1"># read the image and convert it - Set your pathto the image
</span>  <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">imread</span><span class="p">(</span><span class="sh">'</span><span class="s">caretta.png</span><span class="sh">'</span><span class="p">)</span>
  <span class="nf">if </span><span class="p">(</span><span class="nf">type</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="ow">is</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="p">.</span><span class="nf">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)]</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">img:</span><span class="sh">'</span><span class="p">,</span> <span class="n">img</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">image not found - set your path to the image</span><span class="sh">'</span><span class="p">)</span>
  
  <span class="k">return</span> <span class="n">img</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>
<p>We do make use of the
<mark style="background-color:Lavender;">OpenCV</mark> library to read
the <mark style="background-color:Lavender;">caretta.png</mark> image from <mark>files/</mark>.
You can check all the provided images or download one from the web.</p>

<p>Note that you could do the same by using torchvision datasets and
transforms. We will show an example of that when we will use the
<mark style="background-color:Lavender;">LIME</mark> explainer for our
lab exercise at the end of this tutorial.</p>

<h3 id="image-pre-processing">Image pre-processing</h3>

<p>As usual, we will need to normalize our input image. The normalization
is done using the mean and standard deviation of the ImageNet dataset.
The image is also transposed to the correct tensor format:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre></td>
<td class="rouge-code"><pre><span class="k">def</span> <span class="nf">pre_processing</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">cuda</span><span class="p">):</span>
    <span class="c1"># Students should transpose the image to the correct tensor format. 
</span>    <span class="c1"># Students should ensure that gradient for input is calculated       
</span>    <span class="c1"># set the GPU device
</span>    <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
        <span class="n">torch_device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cuda:0</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">torch_device</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">device</span><span class="p">(</span><span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">)</span>

    <span class="c1"># normalise for ImageNet
</span>    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]).</span><span class="nf">reshape</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="n">obs</span> <span class="o">/</span> <span class="mi">255</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="p">(</span><span class="n">obs</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">std</span>

    <span class="c1"># make tensor format that keeps track of gradient
</span>    <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">transpose</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>       
    <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">expand_dims</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">obs</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
    <span class="n">obs_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch_device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">obs_tensor</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>We can do the same (resizing, normalization and conversion to tensor) by
using the torchvision transform:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td>
<td class="rouge-code"><pre><span class="n">transform</span> <span class="o">=</span> <span class="n">A</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span>
        <span class="n">A</span><span class="p">.</span><span class="nc">Resize</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">),</span>
        <span class="n">A</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]),</span>
        <span class="nc">ToTensorV2</span><span class="p">()])</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>Then, the next that we will do is load the image and preprocess it. We
will also check the prediction of the VGG19 model. Note that the
prediction is correct (E.g. 33 and 34 are â€˜caretta-carettaâ€™ and
â€˜turtleâ€™). The code is the following:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td>
<td class="rouge-code"><pre><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">target_label_idx</span><span class="p">,</span> <span class="n">cuda</span><span class="p">):</span>
    <span class="c1"># Makes prediction after preprocessing image 
</span>    <span class="c1"># Note that output should be torch.tensor on cuda
</span>    <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>                        
    <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># calc output from model 
</span>    <span class="k">if</span> <span class="n">target_label_idx</span> <span class="ow">is</span> <span class="bp">None</span><span class="p">:</span>
      <span class="n">target_label_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">((</span><span class="n">output</span><span class="p">.</span><span class="nf">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="n">target_label_idx</span>
    <span class="n">index</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">tensor</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">int64</span><span class="p">)</span> 
    <span class="k">if</span> <span class="n">cuda</span><span class="p">:</span>
      <span class="n">index</span> <span class="o">=</span> <span class="n">index</span><span class="p">.</span><span class="nf">cuda</span><span class="p">()</span>                     <span class="c1"># calc prediction
</span>    <span class="n">output</span> <span class="o">=</span> <span class="n">output</span><span class="p">.</span><span class="nf">gather</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">index</span><span class="p">)</span>           <span class="c1"># gather functionality of pytorch
</span>    <span class="k">return</span> <span class="n">target_label_idx</span><span class="p">,</span> <span class="n">output</span> 

<span class="nb">input</span> <span class="o">=</span> <span class="nf">pre_processing</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span>          <span class="c1"># preprocess: image (normalise, transpose, make tensor on cuda, requires_grad=True)
</span><span class="nf">print </span><span class="p">(</span><span class="nb">input</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">label</span><span class="p">,</span> <span class="n">output</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">output:</span><span class="sh">'</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">output label:</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>The following code helps you to get the label of the prediction. The label is the index of the class in the ImageNet dataset. The index is used to get the class name from the <mark>.json</mark> file. The <mark>.json</mark> file is available in the repository.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre></td>
<td class="rouge-code"><pre><span class="n">idx2label</span><span class="p">,</span> <span class="n">cls2label</span><span class="p">,</span> <span class="n">cls2idx</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">{},</span> <span class="p">{}</span>
<span class="k">with</span> <span class="nf">open</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="nf">abspath</span><span class="p">(</span><span class="sh">'</span><span class="s">imagenet_class_index.json</span><span class="sh">'</span><span class="p">),</span> <span class="sh">'</span><span class="s">r</span><span class="sh">'</span><span class="p">)</span> <span class="k">as</span> <span class="n">read_file</span><span class="p">:</span>
    <span class="n">class_idx</span> <span class="o">=</span> <span class="n">json</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">read_file</span><span class="p">)</span>
    <span class="n">idx2label</span> <span class="o">=</span> <span class="p">[</span><span class="n">class_idx</span><span class="p">[</span><span class="nf">str</span><span class="p">(</span><span class="n">k</span><span class="p">)][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">class_idx</span><span class="p">))]</span>
    <span class="n">cls2label</span> <span class="o">=</span> <span class="p">{</span><span class="n">class_idx</span><span class="p">[</span><span class="nf">str</span><span class="p">(</span><span class="n">k</span><span class="p">)][</span><span class="mi">0</span><span class="p">]:</span> <span class="n">class_idx</span><span class="p">[</span><span class="nf">str</span><span class="p">(</span><span class="n">k</span><span class="p">)][</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">class_idx</span><span class="p">))}</span>
    <span class="n">cls2idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">class_idx</span><span class="p">[</span><span class="nf">str</span><span class="p">(</span><span class="n">k</span><span class="p">)][</span><span class="mi">0</span><span class="p">]:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">class_idx</span><span class="p">))}</span> 
</pre></td>
</tr></tbody></table></code></pre></div></div>

<h2 id="lime-explanation">LIME explanation</h2>
<p>The following figure illustrates the basic idea behind LIME. The figure
shows light pink and blue areas which are the decision boundaries for
the classifier (for the VGG19 pre-trained model on ImageNet for
instance). <mark style="background-color:Lavender;">LIME</mark> can
provide explanations for the predictions of an individual instance (the
one with the dark red dot). These explanations are created by generating
a new dataset of perturbations around the instance to be explained (in
our image are depicted with dot circles around the initial instance).</p>

<figure>

  <picture>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/2023-05-13-LIME/LIME.png" class="img-fluid" width="auto" height="auto" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

<p>Then, we apply our
<mark style="background-color:Lavender;">black-box</mark> model
<mark style="background-color:Lavender;">$g()$</mark> and we can extract
the label for all the perturbations (and can be seen with red that
denotes turtle and purple that denotes non-turtle). The
<em>importance</em> of each perturbation is determined by measuring its
distance from the original instance to be explained
(<mark style="background-color:Lavender;">. These distances are
converted to weights by mapping the distances to a zero-one scale using
a kernel function ($\pi_{\mathbf{x}}$ </mark>). All this information:
the newly generated dataset, its class predictions and its weights are
used to fit a simple model, such as a linear model (gray line), that can
be interpreted. The coefficients for this model are extracted and used
as the explanation for the prediction of the instance we want to
explain. The higher the coefficient, the more important the feature is
for the prediction.</p>

<h2 id="creating-perturbations-of-image">Creating Perturbations of image</h2>

<p>In the case of image explanations, our perturbations will be generated
by zeroing out some of the superpixels in the image.</p>

<h4 id="extract-super-pixels-from-the-image">Extract super-pixels from the image</h4>

<p>The superpixels are generated using the
<mark style="background-color:Lavender;">quickshift</mark> segmentation
algorithm. This algorithm is provided by the
<mark style="background-color:Lavender;">skimage.segmentation</mark>
library. It can be noted that for the given image,
<mark style="background-color:Lavender;">68</mark> superpixels were
generated. That of course will change if you will update the
<mark style="background-color:Lavender;">quickshift</mark> parameters
(<mark style="background-color:Lavender;">kernel_size</mark> and
<mark style="background-color:Lavender;">max_dist</mark>). The code
snippet can be found below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td>
<td class="rouge-code"><pre><span class="kn">import</span> <span class="n">skimage.io</span> 
<span class="kn">import</span> <span class="n">skimage.segmentation</span>

<span class="n">superpixels</span> <span class="o">=</span> <span class="n">skimage</span><span class="p">.</span><span class="n">segmentation</span><span class="p">.</span><span class="nf">quickshift</span><span class="p">(</span><span class="n">img</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">max_dist</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">ratio</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">num_superpixels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">unique</span><span class="p">(</span><span class="n">superpixels</span><span class="p">).</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">num_superpixels</span>

<span class="n">imgplot</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="n">skimage</span><span class="p">.</span><span class="n">segmentation</span><span class="p">.</span><span class="nf">mark_boundaries</span><span class="p">(</span><span class="n">img</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span> <span class="n">superpixels</span><span class="p">))</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">axis</span><span class="p">(</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>

</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>The generated superpixels for the input Caretta-caretta image are shown
in the image below. Note that you can improve the result of the approach
or use another method for creating the superpixels.</p>

<p><img src="../../../assets/img/2023-05-13-LIME/caretta_2.jpg" style="width:400px;height:400px;" class="center"></p>

<h3 id="creating-random-perturbations">Creating random perturbations</h3>
<p>In this example, 14 super-pixels were used. However, for real-life
applications, a larger number of super-pixels will produce more
reliable explanations.</p>

<p>Having extracted the super-pixels, the way that perturbations are calculated is the following: Random
zeros and ones are generated and shaped as a matrix with perturbations
as rows and superpixels as columns. An example of a perturbation (the
first one) is shown below. Here, <code class="language-plaintext highlighter-rouge"><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td>
<td class="rouge-code"><pre>1
</pre></td>
</tr></tbody></table></code> represents that a superpixel is on
and <code class="language-plaintext highlighter-rouge"><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td>
<td class="rouge-code"><pre>0
</pre></td>
</tr></tbody></table></code> represents it is off. Notice that the length of the shown vector
corresponds to the number of superpixels in the image. By running this
code:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td>
<td class="rouge-code"><pre><span class="n">num_perturb</span> <span class="o">=</span> <span class="mi">150</span>
<span class="n">perturbations</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">binomial</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_perturb</span><span class="p">,</span> <span class="n">num_superpixels</span><span class="p">))</span>
<span class="n">perturbations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1">#Show example of perturbation
</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>We can produce this sequence:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td>
<td class="rouge-code"><pre> <span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>The following function <code class="language-plaintext highlighter-rouge"><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td>
<td class="rouge-code"><pre>perturb_image
</pre></td>
</tr></tbody></table></code> perturbs the given image (<code class="language-plaintext highlighter-rouge"><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td>
<td class="rouge-code"><pre>img
</pre></td>
</tr></tbody></table></code>)
based on a perturbation vector (<code class="language-plaintext highlighter-rouge"><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td>
<td class="rouge-code"><pre>perturbation
</pre></td>
</tr></tbody></table></code>) and predefined
superpixels (<code class="language-plaintext highlighter-rouge"><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td>
<td class="rouge-code"><pre>segments
</pre></td>
</tr></tbody></table></code>).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td>
<td class="rouge-code"><pre><span class="k">def</span> <span class="nf">perturb_image</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">perturbation</span><span class="p">,</span><span class="n">segments</span><span class="p">):</span>
  <span class="n">active_pixels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">perturbation</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">segments</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="c1">#Add your code here
</span>  <span class="k">return</span> <span class="n">perturbed_image</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>Letâ€™s use the previous function to see what a perturbed image would look like:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td>
<td class="rouge-code"><pre><span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="nf">perturb_image</span><span class="p">(</span><span class="n">img</span><span class="o">/</span><span class="mi">255</span><span class="p">,</span><span class="n">perturbations</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="n">superpixels</span><span class="p">))</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p><img src="../../../assets/img/2023-05-13-LIME/caretta_3.jpg" style="width:400px;height:400px;" class="center"></p>

<h3 id="step-2-use-ml-classifier-to-predict-classes-of-newly-generated-images">Step 2: Use ML classifier to predict classes of newly generated images</h3>

<p>This is the most computationally expensive step in LIME because a
prediction for each perturbed image is computed. Our aim is to construct a label for each pertubation. From the shape of the
predictions, we can see for each of the perturbations we have the output
probability for each of the 1000 classes.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td>
<td class="rouge-code"><pre><span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">pert</span> <span class="ow">in</span> <span class="n">perturbations</span><span class="p">:</span>
  <span class="n">perturbed_img</span> <span class="o">=</span> <span class="nf">perturb_image</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">pert</span><span class="p">,</span><span class="n">superpixels</span><span class="p">)</span>
  <span class="nb">input</span> <span class="o">=</span> <span class="nf">pre_processing</span><span class="p">(</span><span class="n">perturbed_img</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span>   
  <span class="c1"># preprocess: image (normalise, transpose, make tensor on cuda, requires_grad=True)
</span>  <span class="n">output</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="nf">predict</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="bp">None</span><span class="p">,</span> <span class="n">cuda</span><span class="p">)</span>
  
  <span class="n">output</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>                        
  <span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
  <span class="nf">print </span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">target_label_idx</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="mi">1</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>
  
  <span class="n">predictions</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">output</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">())</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span>
<span class="n">predictions</span><span class="p">.</span><span class="n">shape</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>Then, we will need to calculate the distances between the perturbations
and the original image. The distances are calculated using the cosine
distance. The smaller the distance, the more similar the vectors are.
The distances are then converted to weights using a kernel function.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td>
<td class="rouge-code"><pre><span class="n">original_image</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="n">num_superpixels</span><span class="p">)[</span><span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">,:]</span> <span class="c1">#Perturbation with all superpixels enabled 
</span><span class="n">distances</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="nf">pairwise_distances</span><span class="p">(</span><span class="n">perturbations</span><span class="p">,</span><span class="n">original_image</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="sh">'</span><span class="s">cosine</span><span class="sh">'</span><span class="p">).</span><span class="nf">ravel</span><span class="p">()</span>
<span class="n">distances</span><span class="p">.</span><span class="n">shape</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>As we have shown before, after calculating the distances we need to apply
kernels to use them in the loss function. The employed can is as
follows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td>
<td class="rouge-code"><pre><span class="n">kernel_width</span> <span class="o">=</span> <span class="mf">0.25</span>	
<span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="p">(</span><span class="n">distances</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">kernel_width</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="c1">#Kernel function 
</span><span class="n">weights</span><span class="p">.</span><span class="n">shape</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>
<p>Having calculated the proximity of each perturbation from the original image, as a final step we can calculate the explanation for our predictions. To do that, we will train the explainer using the generated perturbations. Finally, we will need to keep the five highest values in our calculated weights.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td>
<td class="rouge-code"><pre><span class="n">out</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>     
<span class="nf">print </span><span class="p">(</span><span class="n">out</span><span class="p">.</span><span class="n">shape</span><span class="p">)</span>                
<span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="p">.</span><span class="nf">softmax</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>    

<span class="n">out</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">sort</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">descending</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">top_values</span> <span class="o">=</span> <span class="n">out</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]</span> <span class="c1"># Keep the first 5 values from each row
</span><span class="n">top_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]</span>   <span class="c1"># Keep the corresponding indices
</span>
<span class="n">top5</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nf">topk</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="n">topk_values</span> <span class="o">=</span> <span class="n">top_values</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>
<span class="n">topk_indices</span> <span class="o">=</span>  <span class="n">top_indices</span><span class="p">.</span><span class="nf">detach</span><span class="p">().</span><span class="nf">numpy</span><span class="p">()</span>

<span class="nf">print</span><span class="p">(</span><span class="n">topk_values</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">topk_indices</span><span class="p">)</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>We can now train the linear model using the perturbations and the
predictions with the highest probability. The extracted coefficients (or
the explainer model weights) of the linear model are the explanations
for the predictions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td>
<td class="rouge-code"><pre><span class="n">simpler_model</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="c1">#simpler_model.fit()
</span><span class="n">coeff</span> <span class="o">=</span> <span class="n">simpler_model</span><span class="p">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">coeff</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>We can now visualise the top features that the classifier used to make its prediction. The top features are the superpixels that have the highest coefficients.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td>
<td class="rouge-code"><pre><span class="n">num_top_features</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">top_features</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argsort</span><span class="p">(</span><span class="n">coeff</span><span class="p">)[</span><span class="o">-</span><span class="n">num_top_features</span><span class="p">:]</span> 
<span class="n">top_features</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>
<p>Having calculated the top features, we can now create a mask that will highlight the top superpixels in the image.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre></td>
<td class="rouge-code"><pre><span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">num_superpixels</span><span class="p">)</span> 
<span class="n">mask</span><span class="p">[</span><span class="n">top_features</span><span class="p">]</span><span class="o">=</span> <span class="bp">True</span> <span class="c1">#Activate top superpixels
</span><span class="n">skimage</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="nf">imshow</span><span class="p">(</span><span class="nf">perturb_image</span><span class="p">(</span><span class="n">img</span> <span class="p">,</span><span class="n">mask</span><span class="p">,</span><span class="n">superpixels</span><span class="p">)</span> <span class="p">)</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p><img src="../../../assets/img/2023-05-13-LIME/caretta_4.jpg" style="width:400px;height:400px;" class="center"></p>

<h1 id="lab-exercise-tosubmit">Lab exercise <mark>TOSUBMIT</mark>
</h1>

<p>This part of the tutorial is a lab exercise where you will use LIME to
debias a classifier. The goal is to understand how LIME can be used to
explain the behavior of a classifier and how we can use this information
to debias the classifier.</p>

<p>The classifier is trained to classify images of <em>huskies</em> and
<em>wolves</em>. The classifier is a
<mark style="background-color:Lavender;"> black-box $f(.)$</mark> so we
do not have access to its internal states. We have zero knowledge of the training dataset
but also of the classifierâ€™s architecture.</p>

<p>We hope that we will be able to identify the biases in the classifier and
try to debias it using LIME explainer.</p>

<p>We will need to explain the behavior of the classifier
using images from huskies and wolves. You should make use also the
images that you can find on the Canvas page of the course or from google
colab page. If you want you can use also your own husky and wolf images.</p>

<p>Firstly, we will load the classifier and the images we want to explain.
The following code checks the performance of the classifier in a test
set.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre></td>
<td class="rouge-code"><pre><span class="k">def</span> <span class="nf">check_accuracy</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">num_samples</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
    
    <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
            
            <span class="n">scores</span> <span class="o">=</span> <span class="nf">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="n">scores</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            
            <span class="nf">print </span><span class="p">(</span><span class="sh">"</span><span class="s">prediction </span><span class="sh">"</span><span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">predictions</span><span class="p">)</span> <span class="o">+</span> <span class="sh">"</span><span class="s"> label </span><span class="sh">"</span> <span class="o">+</span> <span class="nf">str</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
            <span class="n">num_correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">==</span> <span class="n">y</span><span class="p">).</span><span class="nf">sum</span><span class="p">()</span>
            <span class="n">num_samples</span> <span class="o">+=</span> <span class="n">predictions</span><span class="p">.</span><span class="nf">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Got </span><span class="si">{</span><span class="n">num_correct</span><span class="si">}</span><span class="s"> / </span><span class="si">{</span><span class="n">num_samples</span><span class="si">}</span><span class="s"> with accuracy </span><span class="si">{</span><span class="nf">float</span><span class="p">(</span><span class="n">num_correct</span><span class="p">)</span><span class="o">/</span><span class="nf">float</span><span class="p">(</span><span class="n">num_samples</span><span class="p">)</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="p">.</span><span class="mi">2</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span> 
    
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>Now we will load the classifier, load the images and check the performance of the classifier.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
</pre></td>
<td class="rouge-code"><pre><span class="n">torch</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="sh">'</span><span class="s">model/hus_wolf_model.pth</span><span class="sh">'</span><span class="p">)</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>The following code loads the images and creates the dataloader. The
dataloader is used to load the images in batches. The images are
preprocessed using the same transformations that were used to train the
classifier. Note that the following code is the same as the one used in
the previous part of the tutorial for preprocessing images.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><table class="rouge-table"><tbody><tr>
<td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td>
<td class="rouge-code"><pre><span class="c1"># create the transformation for all the images
</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">.</span><span class="nc">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="p">.</span><span class="nc">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="nc">RandomCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="nc">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="p">.</span><span class="nc">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span><span class="mf">0.225</span><span class="p">])])</span>

<span class="c1"># Load the images
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">datasets</span><span class="p">.</span><span class="nc">ImageFolder</span><span class="p">(</span><span class="sh">"</span><span class="s">data2/test/</span><span class="sh">"</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>

<span class="n">dataset</span><span class="p">.</span><span class="n">classes</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">husky</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">wolf</span><span class="sh">'</span><span class="p">]</span>
<span class="n">dataset</span><span class="p">.</span><span class="n">class_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">husky</span><span class="sh">'</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span><span class="sh">'</span><span class="s">wolf</span><span class="sh">'</span><span class="p">:</span><span class="mi">1</span><span class="p">}</span>
<span class="n">dataset</span><span class="p">.</span><span class="n">samples</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="nf">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">s</span><span class="p">:</span> <span class="n">s</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">dataset</span><span class="p">.</span><span class="n">samples</span><span class="p">))</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>

<span class="c1"># Check the accuracy of the classifier
</span><span class="nf">check_accuracy</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</pre></td>
</tr></tbody></table></code></pre></div></div>

<p>The expected result should be around <mark style="background-color:Lavender;">36%</mark> accuracy.</p>

<p>As a <em>lab exercise</em>, and by using the LIME algorithm established
in previous cells, you should explain the behavior of the classifier.
You should use the provided images in <mark>data/test/</mark> folder.
<mark style="background-color:Lavender;"> Add your conclusions about the
model $f()$</mark>. What are the main problems with this classifier?
Letâ€™s discuss the results during the Werkcollege.</p>

<h1 id="you-should-not-trust-me-tosubmit">You should not trust me! <mark>TOSUBMIT</mark>
</h1>

<p>Now you feel like a <em>hacker</em> and you would like to fool LIME
explanations by constructing adversarial classifiers. To do that we will
follow the process that is described in the following paper [4]. You
can find a detailed also explanation in the following video:</p>

<p><a href="https://www.youtube.com/watch?v=qCYAKmFFpbs&amp;ab_channel=MLExplained-AggregateIntellect-AI.SCIENCE" title="You should not trust me!" rel="external nofollow noopener" target="_blank"><img src="../../../assets/img/2023-05-13-LIME/fooling_LIME.PNG" alt="You should not trust me!"></a></p>

<p>This part of the tutorial is the third part of the assignment you need to
  <mark>TOSUBMIT</mark>. The goal is to understand the limitations of LIME
  and how we can take advantage of them to perform adversarial attacks.
  The main focus is to understand the way that LIME generates samples (the
  perturbations and the distribution of the perturbations in comparison
  with the real data).</p>

<p>The setup is the following:</p>

<p>As an adversary hacker, you intend to deploy the biased
  classifier $f$ for making a <em>critical decision</em> (e.g., confusing
  huskies with wolves ðŸ˜±) in the real world. The adversary must provide
  black-box access to customers and examiners, who may use post hoc
  explanation techniques to better understand $f$ and determine if $f$ is
  ready to be used in the real world. If customers and regulators detect
  that $f$ is biased, they are not likely to approve it for deployment.
  The goal of the adversary is to fool post hoc explanation techniques and
  hide the underlying biases of $f$.</p>

<p>In this assignment, check you need to illustrate the difference between the distribution of real samples and the perturbations. Find a way to illustrate that in an example of your choice.</p>

<p><mark>Optionally</mark>, you should create a scaffolded classifier $e$ that
  behaves exactly like $f$ when making predictions on instances sampled
  from $X_{dist}$ (real samples) but will not reveal the underlying biases of $f$ when probed with leading post hoc explanation techniques such as LIME.</p>

<p>To do that you will need to follow the steps of the suggested paper. You
  need to find ways to differentiate the real data from the generated data
  and based on that create the scaffolded classifier $e$ that will fool
  LIME.</p>

<p>For this assignment, you will need to read the proposed paper and think of ways to perform adversarial attacks using the provided model. Add in your report an explanation of the procedure and the image with the difference between the 2 distributions. Optionally you can add examples of how the classifier $e$ can work in our case.</p>

<h2 id="guidelines-for-the-canvas-submissions">Guidelines for the Canvas submissions:</h2>

<ul>
  <li>You should prepare a report based on researching the <mark>TOSUBMIT</mark> from both notebooks.</li>
  <li>This report should contain three paragraphs. One will be about Integrated gradient and the questions that can be found at the end of the first notebook, one for the LIME explanations and finally one about adversarial attacks.</li>
  <li>Optionally, you should add one paragraph with the results of a scaffolding classifier that can fool LIME and some visual results with that.</li>
</ul>

<h1 id="journal-club-for-weeks-2-and-3">Journal club for weeks 2 and 3</h1>

<p>The papers for weeks 2 and 3 can be found on Canvas at the following links:</p>

<ul>
  <li>https://arxiv.org/pdf/1711.11279.pdf</li>
  <li>https://openaccess.thecvf.com/content/CVPR2021/papers/Chefer_Transformer_Interpretability_Beyond_Attention_Visualization_CVPR_2021_paper.pdf</li>
</ul>

<h1 id="mini-project-ideas">Mini-project ideas</h1>

<p>This part of the tutorial relates to ideas about extending parts of this tutorial. One point of criticism of the LIME technique is the way that the perturbations are taking place since the distributions between real and generated data are significantly different. Think of ways to improve the gap (using alternative ways to perform perturbations).</p>
<ul>
  <li>Think of ways to improve the feature repressions (replacing super-pixels).</li>
  <li>Another direction could be to come up with an evaluation scheme and perform a study comparing LIME, IG or other methods for explainable AI.</li>
</ul>

<h1 id="conclusions">Conclusions</h1>

<p>In this tutorial, we have analyzed LIME a posthoc XAI technique. An explanation of how this technique works but also step-by-step the code to implement it. We have also seen how we can use LIME to explain image classifiers but also how to identify the bias in a classifier.</p>

<h1 id="references">References</h1>
<p style="font-size: smaller"><a href="https://arxiv.org/pdf/1602.04938.pdf" rel="external nofollow noopener" target="_blank">[1] Ribeuro, M.T. et al. Why Should I Trust You? Explaining the Predictions of Any Classifier, 2016. SIGKDD.</a></p>

<p style="font-size: smaller"><a href="https://arxiv.org/pdf/2205.11487" rel="external nofollow noopener" target="_blank">[2] Slack, D. et al. Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods, 2020, AIES â€˜20: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society</a></p>

<p style="font-size: smaller"><a href="https://arxiv.org/pdf/2205.11487" rel="external nofollow noopener" target="_blank">[3] Slack, D. et al. Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods, 2020, AIES â€˜20: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society</a></p>

<p style="font-size: smaller"><a href="https://arxiv.org/pdf/2205.11487" rel="external nofollow noopener" target="_blank">[4] Slack, D. et al. Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods, 2020, AIES â€˜20: Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society</a></p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

      <d-bibliography src="/assets/bibliography/"></d-bibliography>
</div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2024 Christos  Athanasiadis. 
      </div>
    </footer>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
